# üöÄ RaGME_UP - PROP

Syst√®me RAG (Retrieval-Augmented Generation) pour l'indexation et l'interrogation de documents techniques avec FAISS, Snowflake Arctic Embeddings et DALLEM. Inclut un syst√®me de feedback utilisateur avec re-ranking intelligent.

---

## üìñ Documentation

- **[Guide Utilisateur](GUIDE_UTILISATEUR.md)** - Documentation compl√®te pour utiliser l'application
- **[Installation R√©seau](INSTALLATION_RESEAU.md)** - Guide de d√©ploiement multi-utilisateurs
- **[Architecture Technique](ARCHITECTURE_TECHNIQUE.md)** - Documentation technique compl√®te (chunking, parsers, pipeline)

---

## ‚ö° D√©marrage rapide

### Installation

```bash
# Windows: double-cliquez sur
install.bat
```

### Lancement

```bash
# Windows: double-cliquez sur
launch.bat

# Ou manuellement
streamlit run streamlit_RAG.py
```

L'application s'ouvre automatiquement dans votre navigateur sur `http://localhost:8501`

---

## ‚ú® Fonctionnalit√©s principales

- üìù **Gestion CSV** avec interface GUI moderne
- üì• **Ingestion documents** (PDF, DOCX, DOC, TXT) avec tracking automatique
- üîÑ **Mise √† jour globale** : bouton pour traiter tous les CSV en une fois
- üåê **Ingestion Confluence** : chargement d'espaces entiers via API *(admin)*
- ‚úàÔ∏è **Mode EASA automatique** : activ√© automatiquement pour la base CERTIFICATION
- üîí **Coordination multi-utilisateurs** avec syst√®me de verrous
- üóëÔ∏è **Purge des bases** FAISS *(admin)*
- ‚ùì **Questions RAG** avec recherche s√©mantique et g√©n√©ration de r√©ponses
- üíæ **Cache local** : copie locale des bases pour performances r√©seau optimales
- üìñ **Documentation int√©gr√©e** : acc√®s aux guides sous le titre principal
- üìù **Feedback utilisateur** : √©valuation granulaire des r√©ponses et sources
- üîÑ **Re-ranking intelligent** : am√©lioration des r√©sultats bas√©e sur les feedbacks
- üìä **Tableau de bord analytique** : statistiques et tendances *(admin)*
- üë• **Gestion des acc√®s** : onglets et configuration restreints √† l'administrateur

---

## üß† Am√©liorations Qualit√© RAG (v2.0)

### Phase 1 - Retrieval am√©lior√©

| Technique | Description | Fichier |
|-----------|-------------|---------|
| **HyDE** | G√©n√®re une r√©ponse hypoth√©tique pour enrichir la requ√™te | `rag_query.py` |
| **Lost in Middle** | R√©ordonne les chunks (meilleurs en d√©but/fin) | `rag_query.py` |
| **OCR Quality Detection** | √âvalue la qualit√© d'extraction PDF | `pdf_processing.py` |

### Phase 2 - Recherche hybride & Cache

| Technique | Description | Activation |
|-----------|-------------|------------|
| **Hybrid Search (BM25)** | Combine recherche dense + lexicale | Auto si > 1000 chunks |
| **Semantic Cache** | Cache r√©ponses pour requ√™tes similaires | `use_semantic_cache=True` |
| **RAGAS Metrics** | M√©triques qualit√© (faithfulness, relevance) | `compute_metrics=True` |

### Phase 3 - Qualit√© des r√©ponses

| Technique | Description | Fichier |
|-----------|-------------|---------|
| **Answer Grounding** | D√©tection d'hallucinations par v√©rification des claims | `answer_grounding.py` |
| **Query Understanding** | Analyse d'intention (d√©finition, proc√©dure, requirement) | `query_understanding.py` |
| **Semantic Chunking** | D√©coupe aux fronti√®res s√©mantiques | `semantic_chunking.py` |

### üîç LLM Vision OCR (DALLEM)

Pour les PDF scann√©s ou de mauvaise qualit√© :

```python
from llm_ocr import ocr_pdf_with_dallem, smart_ocr_with_dallem

# OCR intelligent avec fallback
result = smart_ocr_with_dallem(
    pdf_path="scan.pdf",
    quality_threshold=0.5,  # OCR si qualit√© < 50%
    auto_rotate=True,       # Correction orientation automatique
    smart_rotate=True,      # D√©tection orientation par LLM
)
```

**Fonctionnalit√©s :**
- ‚úÖ D√©tection automatique de l'orientation des pages
- ‚úÖ Correction rotation (0¬∞, 90¬∞, 180¬∞, 270¬∞)
- ‚úÖ Fallback intelligent : classique d'abord, LLM si qualit√© insuffisante

### üì¶ Pipeline d'ingestion optimis√©

Architecture en 2 phases pour minimiser les appels r√©seau :

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    PHASE LOCALE                                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  1. T√©l√©chargement fichiers ‚Üí TEMP/                             ‚îÇ
‚îÇ  2. Extraction pi√®ces jointes                                   ‚îÇ
‚îÇ  3. Extraction texte (pdfplumber/pymupdf)                       ‚îÇ
‚îÇ  4. OCR DALLEM si qualit√© < seuil                               ‚îÇ
‚îÇ  5. Chunking s√©mantique                                         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                    PHASE R√âSEAU (minimale)                       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  6. Embeddings batch (1 appel / 32 chunks)                      ‚îÇ
‚îÇ  7. Insertion FAISS                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

```python
from ingestion_pipeline import quick_ingest

result = quick_ingest(
    file_paths=["doc1.pdf", "doc2.pdf"],
    db_path="/path/to/faiss",
    collection_name="my_docs",
    quality_threshold=0.5,
)
```

### üíæ Auto-configuration m√©moire

Le pipeline d√©tecte automatiquement la RAM disponible et adapte sa configuration :

| RAM | Mode | Workers | Batch | Streaming | Description |
|-----|------|---------|-------|-----------|-------------|
| ‚â§8 Go | Ultra-conservateur | 1 | 4 | ‚úÖ Oui | PC tr√®s limit√©s |
| 8-12 Go | Conservateur | 2 | 8 | ‚úÖ Oui | PC portables |
| 12-16 Go | √âquilibr√© | 4 | 16 | ‚ùå Non | PC standard |
| 16-32 Go | Performance | 6 | 32 | ‚ùå Non | PC performants |
| 32+ Go | Maximum | 8 | 64 | ‚ùå Non | Workstations |

**Mode streaming** : traite chaque fichier enti√®rement avant le suivant, lib√©rant la m√©moire apr√®s chaque fichier. Id√©al pour les gros PDFs sur PC limit√©s.

```python
# Tout est automatique !
from ingestion_pipeline import ingest_documents

result = ingest_documents(
    file_paths=["gros_document_1600_pages.pdf"],
    db_path="/path/to/faiss",
    collection_name="docs",
)
# La configuration optimale est appliqu√©e selon votre RAM
```

**Affichage au d√©marrage :**
```
üîß AUTO-CONFIG: Ultra-conservateur (‚â§8 Go RAM)
   RAM d√©tect√©e: 8.0 Go (disponible: 4.0 Go)

üíæ CONFIGURATION M√âMOIRE AUTO-D√âTECT√âE
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  üìä Mode: Ultra-conservateur (‚â§8 Go RAM)
  üíª RAM totale: 8.0 Go (d√©tect√©e via psutil)
  üìà RAM disponible: 4.0 Go
  ‚öôÔ∏è  Param√®tres appliqu√©s:
     ‚Ä¢ Max workers: 1
     ‚Ä¢ Batch embeddings: 4
     ‚Ä¢ Streaming: ‚úÖ Oui
     ‚Ä¢ GC agressif: ‚úÖ Oui
```

---

## üß© Syst√®me de Chunking Avanc√©

Le syst√®me RAG utilise un **chunking adaptatif intelligent** qui s'adapte automatiquement au type de document et √† la densit√© du contenu.

### D√©tection automatique du type de document

| Type de document | D√©tection | Strat√©gie appliqu√©e |
|------------------|-----------|---------------------|
| **Documents EASA** | Headers `CS 25.xxx`, `AMC`, `GM` | Chunking par sections r√©glementaires |
| **Documents g√©n√©riques** | Tout autre document | Smart chunking avec pr√©servation de structure |

### Techniques de chunking impl√©ment√©es

#### 1. üìä Analyse de densit√© du contenu

Le syst√®me analyse automatiquement chaque document pour d√©tecter sa densit√© :

| Densit√© | Caract√©ristiques | Taille chunk |
|---------|------------------|--------------|
| **very_dense** | Code, formules, tableaux, nombreuses r√©f√©rences | 800 chars |
| **dense** | Texte technique, sp√©cifications, listes | 1200 chars |
| **normal** | Texte standard, prose technique | 1500 chars |
| **sparse** | Narratif, introductions, descriptions | 2000 chars |

**M√©triques analys√©es :**
- Densit√© de termes techniques (80+ mots-cl√©s a√©ronautiques)
- Ratio nombres/formules
- Longueur moyenne des phrases
- Pr√©sence de listes et tableaux
- Densit√© de r√©f√©rences (CS, AMC, GM, FAR, JAR)
- Ratio d'acronymes

#### 2. ‚úàÔ∏è Chunking EASA sp√©cialis√©

Pour les documents r√©glementaires EASA (CS-25, CS-E, etc.) :

```
[CS 25.571 - Damage tolerance and fatigue evaluation of structure]
The evaluation... (contenu de la section)
```

**Fonctionnalit√©s :**
- D√©tection des sections par regex : `CS`, `AMC`, `GM`, `CS-E`, `CS-APU`
- Pr√©servation du contexte `[Section ID - Title]` dans chaque chunk
- D√©coupage intelligent par sous-paragraphes `(a)`, `(b)`, `(1)`, `(2)`
- Fusion automatique des petites sections (<300 chars)
- Pas de red√©coupage des sections d√©j√† petites

#### 3. üìÑ Smart chunking g√©n√©rique

Pour les documents non-EASA :

- **Pr√©servation des headers** : Les titres restent avec leur contenu
- **Pr√©servation des listes** : Ne coupe jamais au milieu d'une liste
- **Coupure aux phrases** : Respecte les fins de phrases
- **Contexte source** : Ajoute `[Source: filename]` pour tra√ßabilit√©
- **Overlap configurable** : Chevauchement pour garder le contexte

#### 4. üè∑Ô∏è Augmentation des chunks

Chaque chunk est enrichi avec des m√©tadonn√©es pour am√©liorer la recherche :

```python
{
    "text": "...",                    # Contenu du chunk
    "keywords": ["fatigue", "CS 25.571", "structure"],  # Mots-cl√©s extraits
    "key_phrases": ["shall be evaluated..."],           # Phrases cl√©s (exigences)
    "density_type": "dense",          # Type de densit√©
    "density_score": 0.45,            # Score de densit√©
    "references_to": ["CS 25.573", "AMC 25.571"]       # R√©f√©rences d√©tect√©es
}
```

**Extraction de mots-cl√©s :**
- Filtrage des stopwords (FR + EN)
- Bonus pour termes techniques a√©ronautiques
- Extraction des codes de r√©f√©rence (CS, AMC, GM)

#### 5. üîó D√©tection des r√©f√©rences crois√©es

Le syst√®me d√©tecte automatiquement les liens entre sections :

**Patterns d√©tect√©s :**
- R√©f√©rences directes : `CS 25.571`, `AMC 25.1309`, `GM 25.631`
- R√©f√©rences contextuelles : `see CS 25.571`, `refer to AMC...`, `in accordance with...`
- R√©f√©rences FAR/JAR : `FAR 25.571`, `JAR 25.571`
- R√©f√©rences internes : `paragraph (a)`, `sub-paragraph (1)`

**Stockage :**
```python
chunk["references_to"] = ["CS 25.573", "AMC 25.571"]  # Max 5 r√©f√©rences
```

#### 6. üîç Expansion de contexte (Query-Time)

Lors de la recherche, le syst√®me enrichit automatiquement les r√©sultats :

| Fonctionnalit√© | Description |
|----------------|-------------|
| **Chunks voisins** | Ajoute les chunks pr√©c√©dent/suivant du m√™me fichier |
| **Chunks r√©f√©renc√©s** | Si un chunk mentionne `CS 25.573`, inclut les chunks de cette section |
| **Index invers√©** | Lookup rapide des chunks par r√©f√©rence |

**Activation :** `use_context_expansion=True` (par d√©faut)

### Architecture du chunking

```
Document
    ‚îÇ
    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  D√©tection type document    ‚îÇ
‚îÇ  (EASA vs G√©n√©rique)        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ                     ‚îÇ
    ‚ñº                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ EASA Parser ‚îÇ    ‚îÇ Smart Chunk ‚îÇ
‚îÇ (sections)  ‚îÇ    ‚îÇ (generic)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ                  ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚îÇ
                ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Analyse densit√© contenu    ‚îÇ
‚îÇ  ‚Üí Adaptation taille chunks ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     Augmentation chunks     ‚îÇ
‚îÇ  (keywords, key_phrases)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  D√©tection cross-r√©f√©rences ‚îÇ
‚îÇ  (CS, AMC, GM, FAR, JAR)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚ñº
        Chunks index√©s
```

### Fichiers concern√©s

| Fichier | R√¥le |
|---------|------|
| `chunking.py` | Toutes les fonctions de chunking et augmentation |
| `easa_sections.py` | Parser de sections EASA (CS/AMC/GM) |
| `rag_ingestion.py` | Orchestration du chunking lors de l'ingestion |
| `rag_query.py` | Context expansion lors des requ√™tes |
| `confluence_processing.py` | API Confluence et conversion HTML‚Üítexte |

---

## üìÑ Syst√®me de Parsing Multi-Format

Le syst√®me supporte l'extraction de texte depuis de multiples formats de documents avec des strat√©gies de fallback robustes.

### Formats support√©s

| Format | Biblioth√®que principale | Fallback | Fonctionnalit√©s sp√©ciales |
|--------|------------------------|----------|---------------------------|
| **PDF** | pdfplumber | pdfminer.six ‚Üí PyMuPDF | **Extraction tableaux**, pi√®ces jointes, nettoyage Unicode |
| **DOCX** | python-docx | - | Tables, sections, paragraphes |
| **DOC** | pywin32 (Word) | - | ‚úÖ Conversion auto via Word, accepte r√©visions, supprime commentaires |
| **XML** | xml.etree.ElementTree | - | Patterns EASA configurables |
| **TXT/MD** | Lecture native | - | D√©tection encodage |
| **CSV** | Lecture native | - | Extraction texte brut |
| **Confluence** | API REST | - | ‚úÖ Espaces entiers, conversion HTML‚Üítexte |

### Parser PDF (`pdf_processing.py`)

Le parser PDF est le plus sophistiqu√© avec une architecture √† triple fallback et extraction de tableaux :

```
PDF Input
    ‚îÇ
    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  pdfplumber             ‚îÇ  ‚Üê Extraction principale (tableaux)
‚îÇ  (texte + tableaux)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ √âchec ou texte suspect?
           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  pdfminer.six           ‚îÇ  ‚Üê Fallback 1
‚îÇ  (extraction texte)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ √âchec ou texte suspect?
           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  PyMuPDF (fitz)         ‚îÇ  ‚Üê Fallback 2 robuste
‚îÇ  (extraction fallback)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Extraction pi√®ces      ‚îÇ  ‚Üê Automatique
‚îÇ  jointes r√©cursive      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Nettoyage Unicode      ‚îÇ  ‚Üê Surrogates, encodages
‚îÇ  & caract√®res sp√©ciaux  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Fonctionnalit√©s cl√©s :**
- **Extraction tableaux** : pdfplumber d√©tecte et formate les tableaux en markdown
- **Extraction pi√®ces jointes** : D√©tecte et extrait r√©cursivement les PDF/fichiers attach√©s
- **Gestion Unicode** : Nettoyage automatique des caract√®res surrogates
- **Multi-encodage** : D√©tection automatique (UTF-8, UTF-16, Latin-1, ISO-8859-1, CP1252)
- **Heuristiques qualit√©** : D√©tecte si l'extraction est fiable

### Parser DOCX (`docx_processing.py`)

Extraction structur√©e des documents Word :

```python
# Modes d'extraction disponibles
docx_to_text(path)                    # Texte complet
extract_paragraphs_from_docx(path)    # Liste des paragraphes
extract_sections_from_docx(path)      # Sections par headers (Heading 1/2)
extract_text_from_tables(path)        # Contenu des tableaux
```

**Fonctionnalit√©s :**
- Pr√©servation des sauts de ligne
- D√©tection des styles de titres (Heading 1/2, Titre 1/2)
- Extraction des tableaux
- Normalisation des espaces

### Parser XML EASA (`xml_processing.py`)

Parser configurable pour les documents XML r√©glementaires :

```python
# Patterns pr√©configur√©s
class SectionPattern(Enum):
    CS_STANDARD = r"CS[-\s]?25[.\s]?\d+"      # CS 25.101, CS-25.101
    AMC = r"AMC[-\s]?25[.\s]?\d+"              # AMC 25.101
    GM = r"GM[-\s]?25[.\s]?\d+"                # GM 25.101
    CS_E = r"CS[-\s]?E[-\s]?\d+"               # CS-E 100
    CS_APU = r"CS[-\s]?APU[-\s]?\d+"           # CS-APU 100
    ALL_EASA = r"(CS|AMC|GM)[-\s]?..."         # Tous patterns
    CUSTOM = "custom"                          # Pattern personnalis√©
```

**Configuration :**
```python
XMLParseConfig(
    pattern_type=SectionPattern.ALL_EASA,
    custom_pattern=None,           # Pour pattern personnalis√©
    include_section_title=True,
    min_section_length=50,
    excluded_tags=['note', 'amendment']
)
```

### Ingestion Confluence (`confluence_processing.py`)

Ingestion directe depuis Confluence Cloud ou Server via l'API REST :

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Connexion Confluence       ‚îÇ
‚îÇ  (URL, user, password/token)‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  R√©cup√©ration pages         ‚îÇ
‚îÇ  de l'espace (pagination)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Conversion HTML ‚Üí Texte    ‚îÇ
‚îÇ  (BeautifulSoup)            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Ingestion dans FAISS       ‚îÇ
‚îÇ  (chunks + embeddings)      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Fonctionnalit√©s :**
- Support Confluence Cloud (atlassian.net) et Server
- Liste automatique des espaces disponibles
- Extraction de toutes les pages d'un espace
- Conversion HTML vers texte propre (tableaux, listes, headers)
- URL de page stock√©e comme chemin logique
- Id√©al pour synchronisation hebdomadaire

**Interface d√©di√©e :**
Onglet "üåê Confluence" dans l'application Streamlit avec :
1. Formulaire de connexion (test de connexion)
2. S√©lection de l'espace (liste ou saisie manuelle)
3. Configuration (base cible, collection)
4. Bouton d'ingestion avec progression

### Chargement unifi√© (`rag_ingestion.py`)

Le syst√®me d√©tecte automatiquement le format et applique le parser appropri√© :

```python
def load_file_content(path, xml_configs=None):
    extension = Path(path).suffix.lower()

    if extension == '.pdf':
        return extract_text_and_attachments(path)
    elif extension == '.docx':
        return docx_to_text(path)
    elif extension == '.doc':
        return extract_text_from_docx(path)  # Conversion auto via Word
    elif extension == '.xml':
        return parse_xml_with_config(path, xml_configs)
    elif extension in ['.txt', '.md']:
        return read_text_file(path)
    elif extension == '.csv':
        return extract_csv_text(path)
```

**Traitement parall√®le :**
- ThreadPoolExecutor pour compatibilit√© Windows
- Nombre de workers = CPU count
- Gestion robuste des erreurs par fichier

---

## ‚öôÔ∏è Configuration des r√©pertoires

L'application n√©cessite plusieurs r√©pertoires de stockage. Au premier lancement, si ces r√©pertoires ne sont pas accessibles, une **page de configuration** s'affiche automatiquement.

### R√©pertoires requis

| R√©pertoire | Description |
|------------|-------------|
| **Bases FAISS** | Stockage des index vectoriels FAISS |
| **CSV ingestion** | Fichiers CSV pour l'ingestion de documents |
| **CSV tracking** | Fichiers de suivi des documents ing√©r√©s |
| **Feedbacks** | Stockage des feedbacks utilisateurs |

### Configuration automatique

1. Au lancement, l'application v√©rifie l'accessibilit√© de tous les r√©pertoires
2. Si un r√©pertoire est manquant ou inaccessible :
   - Une page de configuration s'affiche
   - Vous pouvez **cr√©er les r√©pertoires manquants** automatiquement
   - Ou **modifier les chemins** selon votre environnement
3. La configuration est sauvegard√©e dans `config.json` (fichier local, ignor√© par git)

### Fichier de configuration

```json
{
  "base_root_dir": "C:\\Data\\FAISS_DATABASE\\BaseDB",
  "csv_import_dir": "C:\\Data\\FAISS_DATABASE\\CSV_Ingestion",
  "csv_export_dir": "C:\\Data\\FAISS_DATABASE\\CSV_Tracking",
  "feedback_dir": "C:\\Data\\FAISS_DATABASE\\Feedbacks"
}
```

---

## üîß Param√®tres de Chunking

Les param√®tres de chunking peuvent √™tre ajust√©s dans `chunking.py` et `rag_ingestion.py` :

### Param√®tres par d√©faut

| Param√®tre | Valeur | Description |
|-----------|--------|-------------|
| `base_chunk_size` | 1000 | Taille de base avant adaptation √† la densit√© |
| `min_chunk_size` | 200 | Taille minimale (fusion si inf√©rieur) |
| `max_chunk_size` | 2000-2500 | Taille maximale apr√®s adaptation |
| `overlap` | 100 | Chevauchement entre chunks cons√©cutifs |
| `merge_small_sections` | True | Fusion des sections < 300 caract√®res |

### Tailles adaptatives par densit√©

```python
CHUNK_SIZES = {
    "very_dense": 800,   # Code, formules, tableaux techniques
    "dense": 1200,       # Sp√©cifications, listes de requirements
    "normal": 1500,      # Prose technique standard
    "sparse": 2000       # Narratif, introductions
}
```

### Personnalisation

Pour modifier le comportement par d√©faut, √©ditez `rag_ingestion.py` :

```python
# Ligne ~180
adapted_chunk_size = _get_adaptive_chunk_size(
    text,
    base_size=1000,      # Modifier ici
    min_size=600,        # Modifier ici
    max_size=2000        # Modifier ici
)
```

---

## üìã Pr√©requis

- Python 3.8 ou sup√©rieur
- Windows 10/11 (ou Linux/macOS avec adaptations)
- Acc√®s r√©seau aux APIs : Snowflake (embeddings), DALLEM (LLM), BGE Reranker

---

## üÜò Support

Consultez la documentation pour toute question :
- Questions d'utilisation ‚Üí [Guide Utilisateur](GUIDE_UTILISATEUR.md)
- Installation r√©seau ‚Üí [Installation R√©seau](INSTALLATION_RESEAU.md)
- D√©veloppement/maintenance ‚Üí [Architecture Technique](ARCHITECTURE_TECHNIQUE.md)

**Auteur** : Renaud LOISON

---

**Version:** 1.8
**Derni√®re mise √† jour:** 2025-11-28
